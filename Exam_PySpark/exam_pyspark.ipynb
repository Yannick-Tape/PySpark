{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1852e35-8000-47dc-82bc-73c59ad67839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement effectué : gps_app.csv\n",
      "Téléchargement effectué : gps_user.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q.1. En utilisant la fonction urlretrieve du module urllib.request, \n",
    "écrire une fonction download_file permettant de télécharger un fichier \n",
    "filename depuis l'adresse globale précédente. Appliquer cette fonction \n",
    "aux fichiers que nous voulons télécharger.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# URL de base pour télécharger les fichiers\n",
    "base_url = \"https://assets-datascientest.s3.eu-west-1.amazonaws.com/\"\n",
    "\n",
    "# Fonction pour télécharger un fichier donné\n",
    "def download_file(filename):\n",
    "    url = base_url + filename\n",
    "    urlretrieve(url, filename)\n",
    "    print(f\"Téléchargement effectué : {filename}\")\n",
    "\n",
    "# Application de la fonction aux deux fichiers nécessaires\n",
    "download_file(\"gps_app.csv\")\n",
    "download_file(\"gps_user.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6eb6be-4dec-4909-b2ff-b38c9d5946bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Création de la SparkSession\n",
    "spark = SparkSession.builder.appName(\"ETL_GPS\").getOrCreate()\n",
    "\n",
    "# Lecture du fichier gps_app.csv\n",
    "raw_app = spark.read.option(\"header\", True)\\\n",
    "                    .option(\"inferSchema\", True)\\\n",
    "                    .option(\"escape\", \"\\\"\")\\\n",
    "                    .csv(\"gps_app.csv\")\n",
    "\n",
    "# Lecture du fichier gps_user.csv\n",
    "raw_user = spark.read.option(\"header\", True)\\\n",
    "                     .option(\"inferSchema\", True)\\\n",
    "                     .option(\"escape\", \"\\\"\")\\\n",
    "                     .csv(\"gps_user.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c729ab-87c5-40d2-8178-6cc8511a565f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567884ed-1a0b-48af-9c3d-a04ea2a42a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.2. Dans un premier prétraitement, renommer toutes les colonnes en remplaçant les espaces par des soulignements et les majuscules par des minuscules.\n",
    "\n",
    "# Pour raw_app\n",
    "raw_app = raw_app.toDF(*[col.lower().replace(\" \", \"_\") for col in raw_app.columns])\n",
    "\n",
    "# Pour raw_user\n",
    "raw_user = raw_user.toDF(*[col.lower().replace(\" \", \"_\") for col in raw_user.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92274b-19bc-42b7-9f7f-1f038bc872c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3fbed8-81d8-46e9-ac85-79313bca5c1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPourquoi la moyenne et non la médiane ?\\nLa moyenne est simple à calculer en Spark avec avg().\\nLa distribution n'a pas été indiquée comme fortement biaisée (pas mentionné de gros outliers dans le cours sur la colonne rating), \\ndonc la moyenne est acceptable.\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.3.1 Remplacer les valeurs manquantes dans la colonne rating par la moyenne ou la médiane. Justifier le choix.\n",
    "\"\"\"\n",
    "Pourquoi la moyenne et non la médiane ?\n",
    "La moyenne est simple à calculer en Spark avec avg().\n",
    "La distribution n'a pas été indiquée comme fortement biaisée (pas mentionné de gros outliers dans le cours sur la colonne rating), \n",
    "donc la moyenne est acceptable.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5664cee2-522f-49e0-ba9e-d6b467685fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetMissingValues\u001b[39m(df):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mselect([count(when(isnan(c) \u001b[38;5;241m|\u001b[39m col(c)\u001b[38;5;241m.\u001b[39misNull(), c))\u001b[38;5;241m.\u001b[39malias(c \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_null\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[0;32m---> 23\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m \u001b[43mgetMissingValues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_app\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m missing_values\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m, in \u001b[0;36mgetMissingValues\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetMissingValues\u001b[39m(df):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mselect([count(when(isnan(c) \u001b[38;5;241m|\u001b[39m col(c)\u001b[38;5;241m.\u001b[39misNull(), c))\u001b[38;5;241m.\u001b[39malias(c \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_null\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns])\n",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetMissingValues\u001b[39m(df):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mselect([\u001b[43mcount\u001b[49m(when(isnan(c) \u001b[38;5;241m|\u001b[39m col(c)\u001b[38;5;241m.\u001b[39misNull(), c))\u001b[38;5;241m.\u001b[39malias(c \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_null\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col, isnan\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# 0. Recast la colonne rating pour être sûr qu'elle est numérique\n",
    "raw_app = raw_app.withColumn(\"rating\", col(\"rating\").cast(DoubleType()))\n",
    "\n",
    "# 1. Calculer la moyenne de la colonne \"rating\" en excluant les valeurs nulles\n",
    "rating_average_df = raw_app.filter(col(\"rating\").isNotNull()).select(avg(\"rating\"))\n",
    "rating_average = rating_average_df.first()[0]\n",
    "\n",
    "# 2. Remplacer toutes les valeurs nulles ou nan de la colonne \"rating\" par cette moyenne\n",
    "from pyspark.sql.functions import isnan, when\n",
    "\n",
    "raw_app = raw_app.withColumn(\n",
    "    \"rating\",\n",
    "    when(isnan(col(\"rating\")) | col(\"rating\").isNull(), rating_average).otherwise(col(\"rating\"))\n",
    ")\n",
    "\n",
    "# 3. Vérifier qu'il n'y a plus de valeurs manquantes dans \"rating\"\n",
    "def getMissingValues(df):\n",
    "    return df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c + \"_null\") for c in df.columns])\n",
    "\n",
    "missing_values = getMissingValues(raw_app)\n",
    "missing_values.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20ae809-282d-4c4f-93a1-7204b921a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan, isnull, sum as _sum\n",
    "\n",
    "# Fonction pour récupérer le nombre de NaN et NULL par colonne\n",
    "def getMissingValues(df):\n",
    "    return df.select([\n",
    "        _sum(isnan(c).cast(\"int\")).alias(c) for c in df.columns\n",
    "    ] + [\n",
    "        _sum(isnull(c).cast(\"int\")).alias(c + \"_null\") for c in df.columns\n",
    "    ])\n",
    "\n",
    "# Fonction pour afficher proprement\n",
    "def missingTable(missing_df):\n",
    "    missing_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df62a6-b689-4a0d-b55f-b330415b60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, col, isnan\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# 1. Recast la colonne rating pour être sûr qu'elle est numérique\n",
    "raw_app = raw_app.withColumn(\"rating\", col(\"rating\").cast(DoubleType()))\n",
    "\n",
    "# 2. Recalculer la moyenne sur les ratings non nulls\n",
    "rating_average = raw_app.filter((col(\"rating\").isNotNull()) & (~isnan(\"rating\"))).select(avg(col(\"rating\"))).first()[0]\n",
    "\n",
    "# 3. Remplacer les valeurs nulles de rating par la moyenne\n",
    "raw_app = raw_app.fillna({\"rating\": rating_average})\n",
    "\n",
    "# 4. Vérification\n",
    "getMissingValues(raw_app).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d7bdc-66db-486b-a941-6a6b2f54181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "rating_average_df = raw_app.filter(raw_app.rating.isNotNull()).select(avg(\"rating\"))\n",
    "rating_average = rating_average_df.first()[0]\n",
    "\n",
    "raw_app = raw_app.fillna({\"rating\": rating_average})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b29347-f96c-4834-82af-09bf618d0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "rating_average_df = raw_app.filter(raw_app.rating.isNotNull()).select(avg(\"rating\"))\n",
    "rating_average = rating_average_df.first()[0]\n",
    "\n",
    "raw_app = raw_app.fillna({\"rating\": rating_average})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4562219-696e-4ea2-b330-fa4aa9f6dcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d82864-e090-4097-86e3-fb97f0ff7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.3.2 Remplacer la valeur manquante de la colonne type par la valeur la plus logique. Justifier le choix.\n",
    "\n",
    "\"\"\"\n",
    "dans ce dataset, l'immense majorité des applications sont gratuites.\n",
    "Donc, par logique statistique, on suppose qu'une application avec un type manquant est très probablement gratuite (\"Free\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f1c6d-b34e-452b-bf0c-dcd3496339a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "# 1. Nettoyage : remplacer toutes les valeurs nulles ou NaN de la colonne type par \"Free\"\n",
    "raw_app = raw_app.withColumn(\n",
    "    \"type\",\n",
    "    when(isnan(col(\"type\")) | col(\"type\").isNull(), \"Free\")\\\n",
    "    .otherwise(col(\"type\"))\n",
    ")\n",
    "\n",
    "# 2. Fonctions de vérification\n",
    "def getMissingValues(df):\n",
    "    \"\"\"Renvoie le nombre de valeurs nulles ou NaN pour chaque colonne.\"\"\"\n",
    "    return df.select([\n",
    "        count(when(isnan(c) | col(c).isNull(), c)).alias(c + \"_null\")\n",
    "        for c in df.columns\n",
    "    ])\n",
    "\n",
    "def missingTable(df_missing):\n",
    "    \"\"\"Affiche le tableau des valeurs manquantes.\"\"\"\n",
    "    df_missing.show()\n",
    "\n",
    "# 3. Vérification : affichage des valeurs nulles restantes\n",
    "missing_values_df = getMissingValues(raw_app)\n",
    "missingTable(missing_values_df)\n",
    "\n",
    "# 4. Vérification additionnelle : voir les valeurs distinctes dans la colonne \"type\"\n",
    "raw_app.select(\"type\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8628c3-02bf-467a-b344-c46bb1e8f530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47f0db-c0c8-41dd-aa87-92371db5051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.3.3 Afficher les valeurs uniques prisent par la colonne type.\n",
    "\"\"\"\n",
    "Que remarquez-vous ? \n",
    "Supprimer le problème. Cela réglera aussi la valeur manquante de la colonne content_rating.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee12e8d-7031-44b0-acc6-bffde7fa8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_app.select(\"type\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ad5ee-524f-4a8c-a472-4ca6e810c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D’après ce qu’on vient de voir dans l'affichage (distinct()), \n",
    "# il existe bien \"0\" comme modalité de \"type\" (ce qui n'à aucun sens), mais on ne sait pas encore combien de lignes exactement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d290d6-f465-4b2e-81f2-cd64a0ef1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_app.filter(col(\"type\") == \"0\").show(truncate=False)\n",
    "raw_app.filter(col(\"type\") == \"0\").count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0aeaf-5a35-4efb-941e-8614ae98eafe",
   "metadata": {},
   "source": [
    "# Nous venons de l'afficher et nous constatons qu'il s'agit d'une seule ligne\n",
    "# Cette ligne a \"0\" en type et content \"NULL\" en content_rating.\n",
    "\"\"\"\n",
    "En fait, cette ligne est totalement déréglée :\n",
    "\"1.9\" est dans category ➔ ce n'est pas normal.\n",
    "\"19.0\" est dans rating ➔ totalement incohérent.\n",
    "\"3.0M\" dans reviews ➔ incohérent.\n",
    "\"Free\" dans installs ➔ totalement faux.\n",
    "\"0\" dans type ➔ faux.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaeb718-3df7-4430-aa52-f203046de73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va donc la supprimer :\n",
    "raw_app = raw_app.filter(col(\"type\") != \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11359267-b5a2-4b4c-a753-3b083a5283c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_app.select(\"type\").distinct().show()\n",
    "# on constate que le problème est définitivement résolu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd536e-e9fb-4fd0-84db-ffb8682adee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc9b95-ae59-4623-9736-c125bd724aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.3.4 Remplacer le reste des valeurs manquantes pour la colonne current_ver et la colonne android_ver par leur modalité respective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e7b84-2135-4a33-916e-c67ff3454c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Trouver la modalité majoritaire pour chaque colonne\n",
    "# Pour current_ver\n",
    "mode_current_ver = raw_app.groupBy(\"current_ver\").count().orderBy(\"count\", ascending=False).first()[\"current_ver\"]\n",
    "# Pour android_ver\n",
    "mode_android_ver = raw_app.groupBy(\"android_ver\").count().orderBy(\"count\", ascending=False).first()[\"android_ver\"]\n",
    "\n",
    "print(mode_current_ver)\n",
    "print(mode_android_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480d3c4-8d1a-45b1-92d8-8119737de84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, isnan, isnull\n",
    "\n",
    "# Remplacer les NULL et NaN dans current_ver\n",
    "raw_app = raw_app.withColumn(\n",
    "    \"current_ver\",\n",
    "    when(isnull(\"current_ver\") | isnan(\"current_ver\"), mode_current_ver).otherwise(col(\"current_ver\"))\n",
    ")\n",
    "# Remplacer les NULL et NaN dans android_ver\n",
    "raw_app = raw_app.withColumn(\n",
    "    \"android_ver\",\n",
    "    when(isnull(\"android_ver\") | isnan(\"android_ver\"), mode_android_ver).otherwise(col(\"android_ver\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432aa1e9-f7b0-43e1-815c-2ca7e9856ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3645493-50c1-4c52-ad2f-2fbcce162212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.3.5 Vérifier qu'il ne reste plus de valeurs manquantes grâce à l'application de la commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fd9c9-03d6-40e9-a9bb-56992bb2e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Vérification\n",
    "from pyspark.sql.functions import col, isnan, isnull, sum as _sum\n",
    "\n",
    "# Fonction pour récupérer le nombre de NaN et NULL par colonne\n",
    "def getMissingValues(df):\n",
    "    return df.select([\n",
    "        _sum(isnan(c).cast(\"int\")).alias(c) for c in df.columns\n",
    "    ] + [\n",
    "        _sum(isnull(c).cast(\"int\")).alias(c + \"_null\") for c in df.columns\n",
    "    ])\n",
    "\n",
    "# Fonction pour afficher proprement\n",
    "def missingTable(missing_df):\n",
    "    missing_df.show(truncate=False)\n",
    "\n",
    "getMissingValues(raw_app).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef055b7-209a-4a39-8b2c-f9faa56097ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, col, isnan\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# 1. Recast la colonne rating pour être sûr qu'elle est numérique\n",
    "raw_app = raw_app.withColumn(\"rating\", col(\"rating\").cast(DoubleType()))\n",
    "\n",
    "# 2. Recalculer la moyenne sur les ratings non nulls\n",
    "rating_average = raw_app.filter((col(\"rating\").isNotNull()) & (~isnan(\"rating\"))).select(avg(col(\"rating\"))).first()[0]\n",
    "\n",
    "# 3. Remplacer les valeurs nulles de rating par la moyenne\n",
    "raw_app = raw_app.fillna({\"rating\": rating_average})\n",
    "\n",
    "# 4. Vérification\n",
    "getMissingValues(raw_app).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d8a9b-df3f-43c8-b5ac-6d046cba49a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, count, isnan\n",
    "\n",
    "# Correction de la colonne \"type\" pour remplacer \"0\" par \"Free\"\n",
    "raw_app = raw_app.withColumn(\n",
    "    \"type\",\n",
    "    when(col(\"type\") == \"0\", \"Free\").otherwise(col(\"type\"))\n",
    ")\n",
    "\n",
    "# Vérification que 'type' est maintenant propre\n",
    "def getMissingValues(df):\n",
    "    return df.select([\n",
    "        count(when(isnan(c) | col(c).isNull(), c)).alias(c + \"_null\")\n",
    "        for c in df.columns\n",
    "    ])\n",
    "\n",
    "# Afficher la table des valeurs manquantes\n",
    "missing_values = getMissingValues(raw_app)\n",
    "missing_values.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36e79b-ee42-472d-933d-e9815ac2b20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef79592-ff85-40ce-9c01-c0d10000a49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c80ead-2c6c-4259-90b1-5bf39b942c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d69575-1e7d-48b4-84e8-7acb6a565b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d99ab-f05d-42fe-b3a8-3dc85c07b1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7a20a-4dc1-46dc-b860-fe713b9a03f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0801e-b4bc-4437-94d8-46a396be9baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c30ff-f7ae-46f6-9fda-aeec89222b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88eeb4-cfcf-46ec-8938-fad2dc357860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e359e68-6163-427a-8787-9fc89d5b2630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928266e-4bcf-411c-9f0f-73c26c120f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2313c9-36fd-4448-971b-bfd2c56f0fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302bd116-7855-448f-a538-396278dad07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
